"""
XLearning Agent - UI Logic Bridge
=================================
Connects UI events to the Backend Orchestrator.
Handles: Agent Stream, Tools Events, Exception Management.
"""

import time
import threading
from typing import Generator, Optional, Any

import streamlit as st
from src.agents.orchestrator import Orchestrator, OrchestratorMode
from src.ui.state import add_message, add_trace_event, set_kb_status

# Global Orchestrator instance (lazy loaded)
_ORCHESTRATOR = None

def get_orchestrator(on_event: Optional[Any] = None, mode: Optional[str] = None) -> Orchestrator:
    """Get or create singleton Orchestrator instance."""
    global _ORCHESTRATOR
    if _ORCHESTRATOR is None:
        # User Feedback: Mode should be determined by Intent, not manual toggle.
        # Defaulting to COORDINATED which includes Intent Classification.
        _ORCHESTRATOR = Orchestrator(mode=OrchestratorMode.COORDINATED, on_event=on_event)
    else:
        # Update callback if provided
        if on_event:
            _ORCHESTRATOR.on_event = on_event
            _ORCHESTRATOR.planner.on_event = on_event
            _ORCHESTRATOR.tutor.on_event = on_event
            _ORCHESTRATOR.validator.on_event = on_event
            
    return _ORCHESTRATOR

def handle_chat_input(user_input: str, should_rerun: bool = True) -> None:
    """
    Process user input via Orchestrator.
    This function should be called from the UI thread.
    Args:
        user_input: The text to process.
        should_rerun: Whether to trigger a rerun at the end (set False if inside a callback).
    """
    if not user_input.strip():
        return

    st.session_state.is_processing = True
    st.session_state.stop_requested = False
    
    # 0. Clear previous trace for a clean view
    from src.ui.state import clear_session_trace
    clear_session_trace()
    
    # 1. Add User Message immediately
    add_message(role="user", content=user_input)
    
    # 2. Add assistant message placeholder
    msg_id = add_message(
        role="assistant", 
        content="æ­£åœ¨æ€è€ƒä¸­...", 
        agent="orchestrator", 
        status="streaming"
    )

    # 3. Trigger immediate rerun to show the messages in UI
    # We set a flag so that on the NEXT run, we start the processing.
    st.session_state.pending_chat_query = user_input
    st.session_state.pending_msg_id = msg_id
    
    if should_rerun:
        st.experimental_rerun()

def process_pending_chat(should_rerun: bool = True):
    """Process a query that was added to history but is waiting for LLM."""
    if "pending_chat_query" not in st.session_state or not st.session_state.pending_chat_query:
        return

    user_input = st.session_state.pending_chat_query
    msg_id = st.session_state.pending_msg_id
    
    # Reset pending flags
    st.session_state.pending_chat_query = None
    st.session_state.pending_msg_id = None

    # Define Trace Callback
    import uuid
    current_step_id_container = {"id": "initial"}

    def trace_callback(event_type: str, name: str, detail: str = ""):
        if event_type == "tool_start":
            current_step_id_container["id"] = "step_" + uuid.uuid4().hex[:4]
        from src.ui.state import add_trace_event
        add_trace_event(current_step_id_container["id"], event_type, name, detail)

    # Synchronous Processing (more stable in Streamlit 1.12.0)
    import traceback
    
    print(f"[DEBUG] Starting synchronous processing loop for: {user_input[:20]}...")
    
    # REPLACED WITH NON-BLOCKING UI:
    # The "Thinking..." message is already in the message list with status="streaming".
    try:
        # 4. Get or create orchestrator
        print("[DEBUG] Getting Orchestrator instance...")
        orchestrator = get_orchestrator(on_event=trace_callback)
        
        # Default to coordinated for now as it handles classification
        mode_str = "coordinated"
        current_mode = OrchestratorMode.STANDALONE if mode_str == "standalone" else OrchestratorMode.COORDINATED
        if orchestrator.mode != current_mode:
            orchestrator.switch_mode(current_mode)
        
        trace_callback("progress", "Orchestrator", "æ­£åœ¨å¤„ç†æ‚¨çš„è¾“å…¥...")
        
        # Extract history (last 10 messages, including user message that was just added)
        history = []
        if st.session_state.current_session:
            all_msgs = st.session_state.current_session.get("messages", [])
            # Exclude the very last placeholder message that is currently "æ­£åœ¨æ€è€ƒä¸­..."
            raw_history = all_msgs[:-2] if len(all_msgs) >= 2 else []
            for m in raw_history[-10:]:
                history.append({"role": m["role"], "content": m["content"]})

        # 5. Execute Run
        print(f"[DEBUG] Calling orchestrator.run with input length {len(user_input)} and history length {len(history)}...")
        response = orchestrator.run(user_input, history=history)
        
        print(f"[DEBUG] Response received (length: {len(response) if response else 0})")
        
        if not response:
            response = "æœªç”Ÿæˆä»»ä½•å›å¤ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—æˆ– API Key è®¾ç½®ã€‚"
            
        # 6. Update complete message
        if st.session_state.current_session:
            for msg in st.session_state.current_session["messages"]:
                if msg["id"] == msg_id:
                    msg["content"] = response
                    msg["status"] = "complete"
                    msg["agent"] = "tutor"
                    break
        
        trace_callback("progress", "Orchestrator", "å¤„ç†å®Œæˆã€‚")
        
        # 7. Update Session Logic State â€” æ™ºèƒ½æ£€æµ‹å“åº”ç±»å‹ï¼ŒåŒæ­¥ session çŠ¶æ€
        session = st.session_state.current_session
        if session:
            session["has_input"] = True
            
            # æ£€æµ‹æ˜¯å¦ç”Ÿæˆäº†å­¦ä¹ è®¡åˆ’
            if "å­¦ä¹ è®¡åˆ’" in response or "ğŸ“‹" in response or "é˜¶æ®µ" in response:
                session["plan"] = {"status": "generated"}
            
            # æ£€æµ‹æ˜¯å¦è¿›å…¥å­¦ä¹ é˜¶æ®µ
            if session.get("plan"):
                session["study_progress"] = max(session.get("study_progress", 0), 1)
            
            # æ£€æµ‹æ˜¯å¦è§¦å‘äº† Quizï¼ˆChat ä¸­è¾“å…¥"æµ‹éªŒ"ç­‰å…³é”®è¯ï¼‰
            if "å¼€å§‹æµ‹éªŒ" in response or "ğŸ“ **å¼€å§‹æµ‹éªŒ" in response:
                # Orchestrator é€šè¿‡ TutorAgent.start_quiz() è¿”å›äº†æµ‹éªŒå†…å®¹
                # å°è¯•ä» Orchestrator çš„ Tutor è·å–å½“å‰ quiz æ•°æ®å¹¶åŒæ­¥åˆ° session
                try:
                    tutor = orchestrator.tutor
                    if tutor.current_quiz and tutor.current_quiz.questions:
                        ui_questions = []
                        for i, q in enumerate(tutor.current_quiz.questions):
                            ui_questions.append({
                                "qid": f"q{i+1}",
                                "question": q.question,
                                "options": q.options if q.options else ["A", "B", "C", "D"],
                                "correct_answer": q.correct_answer,
                                "explanation": q.explanation,
                                "topic": q.topic,
                            })
                        session["quiz"]["questions"] = ui_questions
                        session["quiz"]["score"] = None
                        session["quiz"]["wrong_questions"] = []
                        session["quiz"]["answers"] = {}
                        session["quiz_attempts"] = session.get("quiz_attempts", 0) + 1
                except Exception:
                    pass  # Quiz åŒæ­¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

    except Exception as e:
        err_trace = traceback.format_exc()
        if st.session_state.current_session:
            for msg in st.session_state.current_session["messages"]:
                if msg["id"] == msg_id:
                    msg["content"] = f"âš ï¸ å¤„ç†å¤±è´¥: {str(e)}"
                    msg["status"] = "error"
                    msg["error"] = err_trace
                    break
        st.error(f"Execution Error: {e}")
        print(f"[UI Logic Error] {err_trace}")
    
    finally:
        st.session_state.is_processing = False
        from src.ui.state import save_session_data
        save_session_data(st.session_state.current_session_id, st.session_state.current_session)
        
        if should_rerun:
            st.experimental_rerun()

def handle_file_upload(file) -> None:
    """Handle PDF upload via Orchestrator."""
    orchestrator = get_orchestrator()
    try:
        with st.spinner(f"æ­£åœ¨æ·±å…¥åˆ†æ {file.name} å¹¶æ„å»ºä¸“å±çŸ¥è¯†åº“ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åç§’..."):
            content = file.read()
            set_kb_status("parsing", source=file.name)
            
            # Call Orchestrator
            result = orchestrator.process_file(content, file.name)
            
            if result.get("success", False):
                count = result.get("chunks", 0)
                set_kb_status("ready", count=count)
                
                # Sync logic state
                if st.session_state.current_session:
                    st.session_state.current_session["kb_count"] = count
                    st.session_state.current_session["has_input"] = True
                
                add_message("system", result.get("message"), agent="validator")
            else:
                set_kb_status("error", error=result.get("message"))
                add_message("system", result.get("message"), agent="system", status="error")
        
    except Exception as e:
        set_kb_status("error", error=str(e))
        st.error(f"Upload failed: {e}")

def handle_generate_quiz() -> None:
    """
    ç”Ÿæˆæµ‹éªŒ â€” è°ƒç”¨çœŸå®åç«¯ Orchestrator â†’ ValidatorAgentã€‚
    
    å°† ValidatorAgent ç”Ÿæˆçš„ Quiz å¯¹è±¡è½¬æ¢ä¸º UI session æ ¼å¼ï¼Œ
    ç¡®ä¿ Quiz Tab å’Œ Chat å…¥å£ä½¿ç”¨åŒä¸€ä»½æ•°æ®ã€‚
    """
    from src.ui.state import save_session_data, add_trace_event
    import uuid
    
    if not st.session_state.current_session:
        return
    
    st.session_state.is_processing = True
    
    try:
        # 1. è·å– Orchestrator
        def trace_callback(event_type, name, detail=""):
            step_id = "quiz_" + uuid.uuid4().hex[:4]
            add_trace_event(step_id, event_type, name, detail)
        
        orchestrator = get_orchestrator(on_event=trace_callback)
        
        # 2. è·å– RAG å†…å®¹ä½œä¸ºå‡ºé¢˜å‚è€ƒ
        content = ""
        if orchestrator.rag_engine:
            content = orchestrator.rag_engine.build_context(
                orchestrator.domain or "å­¦ä¹ å†…å®¹", k=3
            )
        
        # 3. è°ƒç”¨ ValidatorAgent ç”ŸæˆçœŸå® Quiz
        quiz = orchestrator.validator.generate_quiz(
            topic=orchestrator.domain or "å­¦ä¹ æµ‹éªŒ",
            content=content,
            num_questions=5,
        )
        
        # 4. è½¬æ¢ä¸º UI session æ ¼å¼
        ui_questions = []
        for i, q in enumerate(quiz.questions):
            ui_questions.append({
                "qid": f"q{i+1}",
                "question": q.question,
                "options": q.options if q.options else ["A", "B", "C", "D"],
                "correct_answer": q.correct_answer,
                "explanation": q.explanation,
                "topic": q.topic,
            })
        
        # 5. å†™å…¥ sessionï¼ˆQuiz Tab å’Œ Chat å…±äº«è¿™ä»½æ•°æ®ï¼‰
        st.session_state.current_session["quiz_attempts"] = (
            st.session_state.current_session.get("quiz_attempts", 0) + 1
        )
        st.session_state.current_session["quiz"]["questions"] = ui_questions
        st.session_state.current_session["quiz"]["score"] = None
        st.session_state.current_session["quiz"]["wrong_questions"] = []
        st.session_state.current_session["quiz"]["answers"] = {}
        
        # 6. åŒæ—¶åœ¨èŠå¤©ä¸­æ˜¾ç¤º quiz å¼€å§‹æç¤º
        quiz_msg = f"ğŸ“ **æµ‹éªŒå·²ç”Ÿæˆï¼š{quiz.topic}**\n\nå…± {len(ui_questions)} é“é¢˜ç›®ï¼Œè¯·åˆ‡æ¢åˆ°æµ‹éªŒé¢æ¿ä½œç­”ã€‚"
        add_message("assistant", quiz_msg, agent="validator")
        
        save_session_data(st.session_state.current_session_id, st.session_state.current_session)
        
    except Exception as e:
        import traceback
        add_message("assistant", f"âš ï¸ æµ‹éªŒç”Ÿæˆå¤±è´¥: {str(e)}", agent="validator", status="error")
        print(f"[Quiz Generation Error] {traceback.format_exc()}")
    
    finally:
        st.session_state.is_processing = False
        st.experimental_rerun()


def handle_generate_report() -> None:
    """
    ç”Ÿæˆå­¦ä¹ è¿›åº¦æŠ¥å‘Š â€” è°ƒç”¨çœŸå®åç«¯ Orchestrator â†’ ValidatorAgentã€‚
    
    å°† ProgressReport å†™å…¥ sessionï¼Œä¾› Report Tab å±•ç¤ºå’Œä¸‹è½½ã€‚
    """
    from src.ui.state import save_session_data, add_trace_event
    import uuid
    
    if not st.session_state.current_session:
        return
    
    st.session_state.is_processing = True
    
    try:
        # 1. è·å– Orchestrator
        def trace_callback(event_type, name, detail=""):
            step_id = "report_" + uuid.uuid4().hex[:4]
            add_trace_event(step_id, event_type, name, detail)
        
        orchestrator = get_orchestrator(on_event=trace_callback)
        
        # 2. è°ƒç”¨ ValidatorAgent ç”ŸæˆæŠ¥å‘Š
        report = orchestrator.validator.generate_report(
            domain=orchestrator.domain or "å­¦ä¹ æŠ¥å‘Š",
            file_manager=orchestrator.file_manager,
        )
        
        # 3. å†™å…¥ session
        report_md = report.to_markdown()
        st.session_state.current_session["report"] = {
            "generated": True,
            "content": report_md,
            "ts": __import__("datetime").datetime.now().isoformat(),
        }
        
        # 4. èŠå¤©ä¸­ä¹Ÿæ˜¾ç¤ºæŠ¥å‘Šç”Ÿæˆæç¤º
        add_message("assistant", f"ğŸ“Š **å­¦ä¹ è¿›åº¦æŠ¥å‘Šå·²ç”Ÿæˆï¼**\n\n{report_md}", agent="validator")
        
        save_session_data(st.session_state.current_session_id, st.session_state.current_session)
        
    except Exception as e:
        import traceback
        add_message("assistant", f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", agent="validator", status="error")
        print(f"[Report Generation Error] {traceback.format_exc()}")
    
    finally:
        st.session_state.is_processing = False
        st.experimental_rerun()
