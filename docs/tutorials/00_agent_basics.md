# 模块 0：Agent 基础概念

> 🎯 **目标**：10 分钟快速理解 LLM、Agent、RAG、Tool 的核心概念
> 📖 **适合**：Agent 领域新手，对这些术语还不太熟悉的同学

---

## 1️⃣ LLM（大语言模型）

### 是什么？

**LLM = Large Language Model = 大语言模型**

就是 ChatGPT、通义千问、DeepSeek 这类 AI。你给它一段文字（Prompt），它返回一段文字（Response）。

```
你（Prompt）     →     LLM     →     AI 回复（Response）
"帮我写首诗"    →   [黑盒子]   →    "春风拂面暖，柳絮轻飞扬..."
```

### 核心特点

| 特点 | 说明 |
|------|------|
| **输入输出都是文本** | 本质就是"文本进，文本出" |
| **无记忆** | 每次调用是独立的，不记得上次聊了什么 |
| **知识有截止日期** | 训练数据有时效性，不知道最新信息 |
| **只能"说"，不能"做"** | 不能上网、不能执行代码、不能读文件 |

### 在你项目中的体现

```python
# src/providers/tongyi.py
from langchain_community.chat_models import ChatTongyi

# 这就是一个 LLM
llm = ChatTongyi(model_name="qwen-turbo")

# 给它文本，它返回文本
response = llm.invoke("什么是机器学习？")
```

---

## 2️⃣ Agent（智能代理）

### 是什么？

**Agent = LLM + 决策能力 + 工具调用**

如果说 LLM 只是一个"会说话的嘴"，那 Agent 就是一个"会思考、会行动的助手"。

```
┌─────────────────────────────────────────────────────────┐
│                        Agent                            │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐             │
│  │   LLM   │ ←→ │  决策   │ ←→ │  工具   │             │
│  │ (大脑)  │    │ (思考)  │    │ (手脚)  │             │
│  └─────────┘    └─────────┘    └─────────┘             │
└─────────────────────────────────────────────────────────┘
```

### LLM vs Agent 的区别

| 场景 | 纯 LLM | Agent |
|------|--------|-------|
| "今天北京天气怎么样？" | ❌ "我不知道实时天气" | ✅ 调用天气 API，返回结果 |
| "帮我查一下这个 PDF 的内容" | ❌ "我看不了文件" | ✅ 调用 PDF 解析工具，返回内容 |
| "帮我订明天的机票" | ❌ "我无法操作" | ✅ 调用订票系统 API |

### ReAct 模式（你项目用的核心模式）

Agent 最常用的思考模式叫 **ReAct**（Reasoning + Acting）：

```
用户问题：帮我分析这个 GitHub 项目 https://github.com/langchain-ai/langchain

Agent 思考过程：
┌─────────────────────────────────────────────────────────┐
│ 💭 Thought：用户想了解一个 GitHub 项目                    │
│ ⚡ Action：调用 [GitHub 分析工具]                        │
│ 👀 Observation：获取到 README 内容、技术栈是 Python...    │
│                                                         │
│ 💭 Thought：我已经有了项目信息，可以生成分析报告了         │
│ ⚡ Action：调用 [LLM] 生成分析                           │
│ 👀 Observation：生成了完整的项目分析报告                  │
│                                                         │
│ ✅ Final Answer：这是一个 Python 编写的 LLM 框架...       │
└─────────────────────────────────────────────────────────┘
```

### 在你项目中的体现

你的项目有 3 个主要 Agent：

| Agent | 职责 | 使用的工具 |
|-------|------|-----------|
| **Planner** | 分析学习材料，生成学习计划 | GitHub 分析器、PDF 解析器 |
| **Tutor** | 互动教学、答疑 | RAG 知识检索 |
| **Validator** | 生成测验、评估进度 | Quiz 生成器 |

---

## 3️⃣ Tool（工具）

### 是什么？

**Tool = Agent 可以调用的外部能力**

LLM 本身只能"说"，Tool 让它能"做"。

```
┌─────────────────────────────────────────────────────────┐
│  常见 Tool 类型                                          │
├─────────────────────────────────────────────────────────┤
│  🔍 搜索工具     →  联网搜索最新信息                       │
│  📄 文档工具     →  读取 PDF、Word、网页                   │
│  🧮 计算工具     →  执行代码、数学计算                     │
│  🌐 API 工具     →  调用第三方服务（天气、股票、翻译）       │
│  💾 存储工具     →  读写数据库、文件系统                   │
└─────────────────────────────────────────────────────────┘
```

### 在你项目中的体现

```
你的项目中的 Tool（在 src/specialists/ 目录）：
├── repo_analyzer.py   → GitHub 仓库分析工具
├── pdf_analyzer.py    → PDF 文档解析工具
└── quiz_maker.py      → 测验题目生成工具
```

---

## 4️⃣ RAG（检索增强生成）

### 是什么？

**RAG = Retrieval-Augmented Generation = 检索增强生成**

LLM 的知识有限（截止日期、不知道你的资料），RAG 让它可以"查资料再回答"。

### 工作流程

```
用户问题："Transformer 中的 Attention 机制怎么理解？"

┌─────────────────────────────────────────────────────────┐
│  Step 1: 检索（Retrieval）                               │
│  ┌─────────────┐          ┌─────────────────────────┐   │
│  │ 用户问题    │  ──────→ │ 向量数据库               │   │
│  │ "Attention" │          │ (存储了你上传的 PDF)     │   │
│  └─────────────┘          └─────────────────────────┘   │
│                                   │                      │
│                                   ▼                      │
│                           找到相关段落：                   │
│                           "Attention 允许模型..."         │
└─────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────┐
│  Step 2: 增强生成（Augmented Generation）                │
│  ┌─────────────────────────────────────────────────┐    │
│  │ 系统提示词：                                      │    │
│  │ "根据以下资料回答问题：                           │    │
│  │  资料：Attention 允许模型关注输入序列的不同部分... │    │
│  │  问题：Attention 机制怎么理解？"                  │    │
│  └─────────────────────────────────────────────────┘    │
│                          │                               │
│                          ▼                               │
│                 ┌─────────────────┐                      │
│                 │      LLM        │                      │
│                 └─────────────────┘                      │
│                          │                               │
│                          ▼                               │
│            "Attention 机制就像是让模型学会                │
│             '关注重点'，它会给输入的每个词                 │
│             分配不同的注意力权重..."                       │
└─────────────────────────────────────────────────────────┘
```

### 为什么需要 RAG？

| 问题 | 没有 RAG | 有 RAG |
|------|---------|--------|
| 问你的 PDF 内容 | ❌ "我没看过这个文件" | ✅ 检索 PDF → 精准回答 |
| 问最新新闻 | ❌ "我的知识截止到..." | ✅ 检索新闻 → 实时回答 |
| 问公司内部文档 | ❌ "我不知道你们公司..." | ✅ 检索内部知识库 → 回答 |

### 关键技术点

| 技术 | 作用 | 你项目用的 |
|------|------|-----------|
| **文本切分** | 把长文档切成小块 | RecursiveCharacterTextSplitter |
| **向量化** | 把文本变成向量（数字） | DashScopeEmbeddings |
| **向量存储** | 存储和检索向量 | ChromaDB |
| **相似度检索** | 找最相关的内容 | Top-K 检索 |

### 在你项目中的体现

```python
# src/rag/ 目录就是你的 RAG 实现
# 简化版流程：

# 1. 切分文档
chunks = splitter.split_text("你的 PDF 内容...")

# 2. 向量化并存入 ChromaDB
chroma_db.add_documents(chunks)

# 3. 用户提问时，检索相关内容
relevant_chunks = chroma_db.similarity_search("Attention 机制")

# 4. 把检索结果交给 LLM 回答
answer = llm.chat(f"根据以下资料回答：{relevant_chunks}\n问题：...")
```

---

## 5️⃣ 总结：概念关系图

```
┌─────────────────────────────────────────────────────────────────┐
│                         你的 AI 学习助手                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│    用户输入                                                       │
│       │                                                          │
│       ▼                                                          │
│  ┌─────────┐     调用工具      ┌─────────────────────────────┐   │
│  │  Agent  │ ───────────────→ │  Tool（PDF/GitHub/Quiz）      │   │
│  │ (决策)  │                   └─────────────────────────────┘   │
│  └────┬────┘                                                     │
│       │                                                          │
│       │ 推理                    ┌─────────────────────────────┐   │
│       ├───────────────────────→│  RAG（检索知识库）            │   │
│       │                        └─────────────────────────────┘   │
│       │                                                          │
│       │ 生成回复                                                  │
│       ▼                                                          │
│  ┌─────────┐                                                     │
│  │   LLM   │  ← 核心大脑                                         │
│  └─────────┘                                                     │
│       │                                                          │
│       ▼                                                          │
│    AI 回复                                                        │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 6️⃣ 面试话术

> **Q: 什么是 Agent？和普通 LLM 有什么区别？**
> 
> A: LLM 只是一个语言模型，输入文本输出文本。Agent 在 LLM 基础上加了**决策能力**和**工具调用**。比如用户问"今天北京天气怎么样"，纯 LLM 会说"我不知道实时天气"，但 Agent 会主动调用天气 API 获取实时数据再回答。

> **Q: 什么是 RAG？为什么需要它？**
> 
> A: RAG 是检索增强生成，解决 LLM 的**知识局限性**问题。LLM 的知识有截止日期，也不知道用户的私有资料。通过 RAG，我先把用户的 PDF、文档向量化存入知识库，用户提问时先检索相关内容，再把检索结果作为上下文交给 LLM 回答，这样既利用了 LLM 的推理能力，又保证了答案基于真实资料。

---

## ✅ 模块 0 完成！

你现在应该理解了：
- **LLM**：会说话的大脑，只能文本进文本出
- **Agent**：LLM + 决策 + 工具，能思考能行动
- **Tool**：Agent 的手脚，扩展 LLM 的能力边界
- **RAG**：检索增强生成，让 LLM 能查资料再回答

---

**👉 下一步**：模块 1 - 项目架构设计

准备好了就告诉我 "继续模块1"！
